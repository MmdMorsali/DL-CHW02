{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Deep Learning Course**\n",
    "\n",
    "## **Loss Functions and Multilayer Perceptrons (MLP)**\n",
    "\n",
    "---\n",
    "\n",
    "### **Student Information:**\n",
    "\n",
    "- **Name:** *Mohammad Morsali*\n",
    "- **Student Number:** *400101956*\n",
    "\n",
    "---\n",
    "\n",
    "### **Assignment Overview**\n",
    "\n",
    "In this notebook, we will explore various loss functions used in neural networks, with a specific focus on their role in training **Multilayer Perceptrons (MLPs)**. By the end of this notebook, you will have a deeper understanding of:\n",
    "- Types of loss functions\n",
    "- How loss functions affect the training process\n",
    "- The relationship between loss functions and model optimization in MLPs\n",
    "\n",
    "---\n",
    "\n",
    "### **Table of Contents**\n",
    "\n",
    "1. Introduction to Loss Functions\n",
    "2. Types of Loss Functions\n",
    "3. Multilayer Perceptrons (MLP)\n",
    "4. Implementing Loss Functions in MLP\n",
    "5. Conclusion\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Introduction to Loss Functions \n",
    "\n",
    "In deep learning, **loss functions** play a crucial role in training models by quantifying the difference between the predicted outputs and the actual targets. Selecting the appropriate loss function is essential for the success of your model. In this assay, we will explore various loss functions available in PyTorch, understand their theoretical backgrounds, and provide you with a scaffolded class to experiment with these loss functions.\n",
    "\n",
    "Before begining, let's train a simle MLP model using the **L1Loss** function. We'll return to this model later to experiment with different loss functions. We'll start by importing the necessary libraries and defining the model architecture.\n",
    "\n",
    "First things first, let's talk about **L1Loss**.\n",
    "\n",
    "### 1. L1Loss (`torch.nn.L1Loss`)\n",
    "- **Description:** Also known as Mean Absolute Error (MAE), L1Loss computes the average absolute difference between the predicted values and the target values.\n",
    "- **Use Case:** Suitable for regression tasks where robustness to outliers is desired.\n",
    "\n",
    "Here is the mathematical formulation of L1Loss:\n",
    "\\begin{equation}\n",
    "\\text{L1Loss} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{\\text{pred}_i} - y_{\\text{true}_i}|\n",
    "\\end{equation}\n",
    "\n",
    "Let's implement a simple MLP model using the L1Loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import requests\n",
    "from io import StringIO\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "# Don't be courious about Adam, it's just a fancy name for a fancy optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we'll define a class called `SimpleMLP` that inherits from `nn.Module`. This class can have multiple layers, and we'll use the `nn.Sequential` module to define the layers of the model. The model will have the following architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim, \n",
    "        hidden_dim, \n",
    "        output_dim, \n",
    "        num_hidden_layers=1, \n",
    "        last_layer_activation_fn=nn.ReLU\n",
    "    ):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "\n",
    "        # Initialize a list to store layers\n",
    "        net_layers = []\n",
    "\n",
    "        # Add the input layer with activation\n",
    "        net_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        net_layers.append(nn.ReLU())\n",
    "\n",
    "        # Add specified number of hidden layers with activation\n",
    "        for layer_num in range(1, num_hidden_layers):\n",
    "            net_layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            net_layers.append(nn.ReLU())\n",
    "\n",
    "        # Add the output layer\n",
    "        net_layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "\n",
    "        # Optionally add activation function to the output layer\n",
    "        if last_layer_activation_fn is not None:\n",
    "            net_layers.append(last_layer_activation_fn())\n",
    "\n",
    "        # Create the model using nn.Sequential\n",
    "        self.model = nn.Sequential(*net_layers)\n",
    "\n",
    "        # Initialize weights\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        # Initialize weights for linear layers using Kaiming uniform initialization\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_uniform_(module.weight, nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the model\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a class called `SimpleMLP_Loss` that has the following architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLPTrainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        criterion, \n",
    "        optimizer, \n",
    "        scheduler=None, \n",
    "        save_model=False, \n",
    "        checkpoint_path='model_checkpoint.pth', \n",
    "        writer=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the trainer with model, criterion, optimizer, and optional scheduler and writer.\n",
    "\n",
    "        Args:\n",
    "            model: The neural network model to train.\n",
    "            criterion: Loss function.\n",
    "            optimizer: Optimization algorithm.\n",
    "            scheduler: Learning rate scheduler (optional).\n",
    "            save_model: Whether to save the model when validation loss improves.\n",
    "            checkpoint_path: Path to save the model checkpoint.\n",
    "            writer: TensorBoard SummaryWriter for logging (optional).\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.save_model = save_model\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "        self.best_loss = float('inf')\n",
    "        self.writer = writer\n",
    "\n",
    "    def train(self, train_loader, num_epochs, val_loader=None):\n",
    "        \"\"\"\n",
    "        Train the model using the provided data loader.\n",
    "\n",
    "        Args:\n",
    "            train_loader: DataLoader for training data.\n",
    "            num_epochs: Number of epochs to train.\n",
    "            val_loader: DataLoader for validation data (optional).\n",
    "\n",
    "        Returns:\n",
    "            Tuple of lists containing training losses, validation losses, and validation accuracies.\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        epoch_losses = []\n",
    "        validation_losses = []\n",
    "        validation_accuracies = []\n",
    "\n",
    "        for epoch_idx in range(num_epochs):\n",
    "            running_loss = 0.0\n",
    "            for batch_inputs, batch_targets in tqdm(\n",
    "                train_loader, desc=f\"Epoch {epoch_idx+1}/{num_epochs}\"\n",
    "            ):\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                # Forward pass\n",
    "                predictions = self.model(batch_inputs)\n",
    "                loss = self.criterion(predictions, batch_targets)\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                \n",
    "                running_loss += loss.item()\n",
    "\n",
    "            # Calculate average loss for the epoch\n",
    "            avg_loss = running_loss / len(train_loader)\n",
    "            epoch_losses.append(avg_loss)\n",
    "            \n",
    "            print(f\"Epoch [{epoch_idx+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "            # Step the scheduler if it's provided\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            # Evaluate on validation set if provided\n",
    "            if val_loader is not None:\n",
    "                val_loss, val_accuracy = self.evaluate(val_loader, current_epoch=epoch_idx)\n",
    "                validation_losses.append(val_loss)\n",
    "                validation_accuracies.append(val_accuracy)\n",
    "\n",
    "                # Log validation metrics\n",
    "                if self.writer:\n",
    "                    self.writer.add_scalar('Loss/validation', val_loss, epoch_idx)\n",
    "                    self.writer.add_scalar('Accuracy/validation', val_accuracy, epoch_idx)\n",
    "\n",
    "            # Log training loss\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Loss/train', avg_loss, epoch_idx)\n",
    "\n",
    "            # Save model checkpoint if loss improves\n",
    "            if avg_loss < self.best_loss and self.save_model:\n",
    "                self.best_loss = avg_loss\n",
    "                torch.save(self.model.state_dict(), self.checkpoint_path)\n",
    "                print(f\"Model saved with loss {avg_loss:.4f}\")\n",
    "\n",
    "        return epoch_losses, validation_losses, validation_accuracies\n",
    "\n",
    "    def evaluate(self, val_loader, current_epoch=0):\n",
    "        \"\"\"\n",
    "        Evaluate the model on the validation set.\n",
    "\n",
    "        Args:\n",
    "            val_loader: DataLoader for validation data.\n",
    "            current_epoch: The current epoch number (used for logging).\n",
    "\n",
    "        Returns:\n",
    "            Tuple containing average validation loss and accuracy.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_targets in val_loader:\n",
    "                predictions = self.model(batch_inputs)\n",
    "                loss = self.criterion(predictions, batch_targets)\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Determine if it's binary or multi-class classification\n",
    "                if predictions.dim() == 1 or predictions.shape[1] == 1:\n",
    "                    # Binary classification\n",
    "                    predicted_labels = (predictions >= 0.5).float().squeeze()\n",
    "                    batch_targets = batch_targets.squeeze()\n",
    "                else:\n",
    "                    # Multi-class classification\n",
    "                    predicted_labels = torch.argmax(predictions, dim=1)\n",
    "                    batch_targets = batch_targets.squeeze()\n",
    "                    if batch_targets.dim() > 1:\n",
    "                        batch_targets = torch.argmax(batch_targets, dim=1)\n",
    "\n",
    "                total_correct += (predicted_labels == batch_targets).sum().item()\n",
    "                total_samples += batch_targets.size(0)\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        accuracy = 100 * total_correct / total_samples if total_samples > 0 else 0\n",
    "\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Log validation metrics\n",
    "        if self.writer:\n",
    "            self.writer.add_scalar('Loss/validation', avg_val_loss, current_epoch)\n",
    "            self.writer.add_scalar('Accuracy/validation', accuracy, current_epoch)\n",
    "\n",
    "        return avg_val_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets test our model using the L1Loss function. You'll use <span style=\"color:red\">*Titanic Dataset*</span> to train the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "response = requests.get(train_url, verify=False)\n",
    "data = pd.read_csv(StringIO(response.text))\n",
    "data = data[['Pclass', 'Sex', 'Age', 'Fare', 'Survived']].dropna()\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Extract input features and target labels\n",
    "feature_values = data[['Pclass', 'Sex', 'Age', 'Fare']].values\n",
    "label_values = data['Survived'].values\n",
    "\n",
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(feature_values)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_tensor = torch.tensor(scaled_features, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(label_values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# Create a TensorDataset from tensors\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Calculate sizes for training and validation datasets\n",
    "train_dataset_size = int(0.8 * len(dataset))\n",
    "val_dataset_size = len(dataset) - train_dataset_size\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [train_dataset_size, val_dataset_size]\n",
    ")\n",
    "\n",
    "# Handle class imbalance using WeightedRandomSampler\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "# Calculate class counts and weights\n",
    "class_counts = np.bincount(label_values.astype(int))\n",
    "class_weights = 1. / class_counts\n",
    "sample_weights = class_weights[label_values.astype(int)]\n",
    "\n",
    "# Create a WeightedRandomSampler\n",
    "weighted_sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights, num_samples=len(sample_weights), replacement=True\n",
    ")\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=32, sampler=weighted_sampler\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\"> <span style=\"color:red; font-size: 26px; font-weight: bold;\">Let's train!</span> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Training Loss: 0.4504\n",
      "Validation Loss: 0.4337\n",
      "Validation Accuracy: 59.18%\n",
      "Precision: 0.5000\n",
      "Recall: 0.0172\n",
      "F1 Score: 0.0333\n",
      "Validation loss improved, model saved.\n",
      "Epoch [2/50]\n",
      "Training Loss: 0.4184\n",
      "Validation Loss: 0.4101\n",
      "Validation Accuracy: 59.31%\n",
      "Precision: 1.0000\n",
      "Recall: 0.0172\n",
      "F1 Score: 0.0339\n",
      "Validation loss improved, model saved.\n",
      "Epoch [3/50]\n",
      "Training Loss: 0.3924\n",
      "Validation Loss: 0.3885\n",
      "Validation Accuracy: 58.78%\n",
      "Precision: 1.0000\n",
      "Recall: 0.0862\n",
      "F1 Score: 0.1587\n",
      "Validation loss improved, model saved.\n",
      "Epoch [4/50]\n",
      "Training Loss: 0.3689\n",
      "Validation Loss: 0.3665\n",
      "Validation Accuracy: 57.59%\n",
      "Precision: 1.0000\n",
      "Recall: 0.2414\n",
      "F1 Score: 0.3889\n",
      "Validation loss improved, model saved.\n",
      "Epoch [5/50]\n",
      "Training Loss: 0.3407\n",
      "Validation Loss: 0.3437\n",
      "Validation Accuracy: 56.40%\n",
      "Precision: 0.9565\n",
      "Recall: 0.3793\n",
      "F1 Score: 0.5432\n",
      "Validation loss improved, model saved.\n",
      "Epoch [6/50]\n",
      "Training Loss: 0.3124\n",
      "Validation Loss: 0.3196\n",
      "Validation Accuracy: 55.61%\n",
      "Precision: 0.9310\n",
      "Recall: 0.4655\n",
      "F1 Score: 0.6207\n",
      "Validation loss improved, model saved.\n",
      "Epoch [7/50]\n",
      "Training Loss: 0.2823\n",
      "Validation Loss: 0.3008\n",
      "Validation Accuracy: 54.56%\n",
      "Precision: 0.8378\n",
      "Recall: 0.5345\n",
      "F1 Score: 0.6526\n",
      "Validation loss improved, model saved.\n",
      "Epoch [8/50]\n",
      "Training Loss: 0.2598\n",
      "Validation Loss: 0.2862\n",
      "Validation Accuracy: 53.76%\n",
      "Precision: 0.7674\n",
      "Recall: 0.5690\n",
      "F1 Score: 0.6535\n",
      "Validation loss improved, model saved.\n",
      "Epoch [9/50]\n",
      "Training Loss: 0.2438\n",
      "Validation Loss: 0.2769\n",
      "Validation Accuracy: 53.37%\n",
      "Precision: 0.7391\n",
      "Recall: 0.5862\n",
      "F1 Score: 0.6538\n",
      "Validation loss improved, model saved.\n",
      "Epoch [10/50]\n",
      "Training Loss: 0.2350\n",
      "Validation Loss: 0.2710\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [11/50]\n",
      "Training Loss: 0.2317\n",
      "Validation Loss: 0.2705\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [12/50]\n",
      "Training Loss: 0.2310\n",
      "Validation Loss: 0.2701\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [13/50]\n",
      "Training Loss: 0.2303\n",
      "Validation Loss: 0.2696\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [14/50]\n",
      "Training Loss: 0.2308\n",
      "Validation Loss: 0.2692\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [15/50]\n",
      "Training Loss: 0.2301\n",
      "Validation Loss: 0.2687\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [16/50]\n",
      "Training Loss: 0.2296\n",
      "Validation Loss: 0.2683\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [17/50]\n",
      "Training Loss: 0.2287\n",
      "Validation Loss: 0.2680\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [18/50]\n",
      "Training Loss: 0.2284\n",
      "Validation Loss: 0.2675\n",
      "Validation Accuracy: 53.23%\n",
      "Precision: 0.7447\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n",
      "Epoch [19/50]\n",
      "Training Loss: 0.2294\n",
      "Validation Loss: 0.2671\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [20/50]\n",
      "Training Loss: 0.2280\n",
      "Validation Loss: 0.2668\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [21/50]\n",
      "Training Loss: 0.2286\n",
      "Validation Loss: 0.2667\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [22/50]\n",
      "Training Loss: 0.2274\n",
      "Validation Loss: 0.2667\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [23/50]\n",
      "Training Loss: 0.2266\n",
      "Validation Loss: 0.2667\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [24/50]\n",
      "Training Loss: 0.2267\n",
      "Validation Loss: 0.2666\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [25/50]\n",
      "Training Loss: 0.2278\n",
      "Validation Loss: 0.2666\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [26/50]\n",
      "Training Loss: 0.2282\n",
      "Validation Loss: 0.2666\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [27/50]\n",
      "Training Loss: 0.2282\n",
      "Validation Loss: 0.2665\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [28/50]\n",
      "Training Loss: 0.2276\n",
      "Validation Loss: 0.2665\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [29/50]\n",
      "Training Loss: 0.2280\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [30/50]\n",
      "Training Loss: 0.2273\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [31/50]\n",
      "Training Loss: 0.2274\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [32/50]\n",
      "Training Loss: 0.2273\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [33/50]\n",
      "Training Loss: 0.2278\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [34/50]\n",
      "Training Loss: 0.2271\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [35/50]\n",
      "Training Loss: 0.2264\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [36/50]\n",
      "Training Loss: 0.2273\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [37/50]\n",
      "Training Loss: 0.2273\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [38/50]\n",
      "Training Loss: 0.2270\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [39/50]\n",
      "Training Loss: 0.2268\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [40/50]\n",
      "Training Loss: 0.2265\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [41/50]\n",
      "Training Loss: 0.2272\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [42/50]\n",
      "Training Loss: 0.2260\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [43/50]\n",
      "Training Loss: 0.2267\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [44/50]\n",
      "Training Loss: 0.2271\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [45/50]\n",
      "Training Loss: 0.2265\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [46/50]\n",
      "Training Loss: 0.2281\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [47/50]\n",
      "Training Loss: 0.2272\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [48/50]\n",
      "Training Loss: 0.2269\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [49/50]\n",
      "Training Loss: 0.2270\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Epoch [50/50]\n",
      "Training Loss: 0.2269\n",
      "Validation Loss: 0.2664\n",
      "Validation Accuracy: 53.10%\n",
      "Precision: 0.7292\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6604\n",
      "Validation loss improved, model saved.\n",
      "Validation Loss: 0.2664, Accuracy: 74.83%\n"
     ]
    }
   ],
   "source": [
    "# Using L1 Loss for training the model on the Titanic dataset with improvements\n",
    "\n",
    "\n",
    "# Define model parameters\n",
    "input_dim = feature_values.shape[1]  # Number of input features from the dataset\n",
    "hidden_dim = 16                      # Number of neurons in each hidden layer\n",
    "output_dim = 1                       # Output dimension for binary classification (Survived or not)\n",
    "num_hidden_layers = 2                # Total number of hidden layers in the model\n",
    "\n",
    "# Instantiate the SimpleMLP model\n",
    "model = SimpleMLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    last_layer_activation_fn=nn.Sigmoid  # Use Sigmoid activation for binary classification\n",
    ")\n",
    "\n",
    "# Define the loss function using Mean Absolute Error (L1 Loss)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer with a learning rate of 0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define a learning rate scheduler to adjust the learning rate during training\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Instantiate the SimpleMLPTrainer with the model, loss function, optimizer, and scheduler\n",
    "trainer = SimpleMLPTrainer(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    save_model=True,                   # Save the model when validation loss improves\n",
    "    checkpoint_path='best_model.pth'   # Path to save the best model\n",
    ")\n",
    "\n",
    "# Set the number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "# Implement early stopping parameters\n",
    "early_stopping_patience = 5  # Stop training if validation loss doesn't improve for 5 consecutive epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Lists to store training and validation metrics\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "validation_accuracies = []\n",
    "validation_precisions = []\n",
    "validation_recalls = []\n",
    "validation_f1s = []\n",
    "\n",
    "# Training loop with early stopping and metric tracking\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_training_loss = running_loss / len(train_loader)\n",
    "    training_losses.append(avg_training_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Collect targets and predictions for metrics\n",
    "            predicted = (outputs >= 0.5).float().squeeze()\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    validation_losses.append(avg_val_loss)\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    accuracy = (np.array(all_predictions) == np.array(all_targets)).mean() * 100\n",
    "    precision = precision_score(all_targets, all_predictions)\n",
    "    recall = recall_score(all_targets, all_predictions)\n",
    "    f1 = f1_score(all_targets, all_predictions)\n",
    "    validation_accuracies.append(accuracy)\n",
    "    validation_precisions.append(precision)\n",
    "    validation_recalls.append(recall)\n",
    "    validation_f1s.append(f1)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Training Loss: {avg_training_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # Save the best model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(\"Validation loss improved, model saved.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"No improvement in validation loss for {epochs_without_improvement} epochs.\")\n",
    "\n",
    "    # # Early stopping\n",
    "    # if epochs_without_improvement >= early_stopping_patience:\n",
    "    #     print(\"Early stopping triggered.\")\n",
    "    #     break\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Load the best model before evaluation\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "final_val_loss, final_val_accuracy = trainer.evaluate(val_loader)\n",
    "\n",
    "# # Plot training and validation losses\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(training_losses)+1), training_losses, label='Training Loss')\n",
    "# plt.plot(range(1, len(validation_losses)+1), validation_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss over Epochs')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot validation accuracy, precision, recall, and F1 score\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(validation_accuracies)+1), validation_accuracies, label='Accuracy')\n",
    "# plt.plot(range(1, len(validation_precisions)+1), validation_precisions, label='Precision')\n",
    "# plt.plot(range(1, len(validation_recalls)+1), validation_recalls, label='Recall')\n",
    "# plt.plot(range(1, len(validation_f1s)+1), validation_f1s, label='F1 Score')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Metric')\n",
    "# plt.title('Validation Metrics over Epochs')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Types of Loss Functions\n",
    "\n",
    "PyTorch offers a variety of built-in loss functions tailored for different types of problems, such as regression, classification, and more. Below, we discuss several commonly used loss functions, their theoretical foundations, and typical use cases.\n",
    "\n",
    "### 2. MSELoss (`torch.nn.MSELoss`)\n",
    "- **Description:** Mean Squared Error (MSE) calculates the average of the squares of the differences between predicted and target values.\n",
    "- **Use Case:** Commonly used in regression problems where larger errors are significantly penalized.\n",
    "\n",
    "Here is boring math stuff for MSE:\n",
    "\\begin{equation}\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^{2}\n",
    "\\end{equation}\n",
    "\n",
    "<span style=\"color:red; font-size: 18px; font-weight: bold;\">Warning:</span> Don't forget to reinitialize the model before experimenting with different loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Training Loss: 0.2335\n",
      "Validation Loss: 0.2109\n",
      "Validation Accuracy: 65.03%\n",
      "Precision: 0.5556\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.6154\n",
      "Validation loss improved, model saved.\n",
      "Epoch [2/50]\n",
      "Training Loss: 0.1874\n",
      "Validation Loss: 0.1838\n",
      "Validation Accuracy: 73.43%\n",
      "Precision: 0.6667\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.6780\n",
      "Validation loss improved, model saved.\n",
      "Epoch [3/50]\n",
      "Training Loss: 0.1649\n",
      "Validation Loss: 0.1699\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7407\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7143\n",
      "Validation loss improved, model saved.\n",
      "Epoch [4/50]\n",
      "Training Loss: 0.1526\n",
      "Validation Loss: 0.1635\n",
      "Validation Accuracy: 79.72%\n",
      "Precision: 0.7959\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7290\n",
      "Validation loss improved, model saved.\n",
      "Epoch [5/50]\n",
      "Training Loss: 0.1463\n",
      "Validation Loss: 0.1593\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8125\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7358\n",
      "Validation loss improved, model saved.\n",
      "Epoch [6/50]\n",
      "Training Loss: 0.1411\n",
      "Validation Loss: 0.1571\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8163\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7477\n",
      "Validation loss improved, model saved.\n",
      "Epoch [7/50]\n",
      "Training Loss: 0.1384\n",
      "Validation Loss: 0.1554\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8125\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7358\n",
      "Validation loss improved, model saved.\n",
      "Epoch [8/50]\n",
      "Training Loss: 0.1359\n",
      "Validation Loss: 0.1542\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8125\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7358\n",
      "Validation loss improved, model saved.\n",
      "Epoch [9/50]\n",
      "Training Loss: 0.1344\n",
      "Validation Loss: 0.1532\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [10/50]\n",
      "Training Loss: 0.1332\n",
      "Validation Loss: 0.1527\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [11/50]\n",
      "Training Loss: 0.1324\n",
      "Validation Loss: 0.1526\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [12/50]\n",
      "Training Loss: 0.1316\n",
      "Validation Loss: 0.1525\n",
      "Validation Accuracy: 79.72%\n",
      "Precision: 0.8085\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7238\n",
      "Validation loss improved, model saved.\n",
      "Epoch [13/50]\n",
      "Training Loss: 0.1320\n",
      "Validation Loss: 0.1525\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [14/50]\n",
      "Training Loss: 0.1318\n",
      "Validation Loss: 0.1524\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [15/50]\n",
      "Training Loss: 0.1319\n",
      "Validation Loss: 0.1523\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [16/50]\n",
      "Training Loss: 0.1313\n",
      "Validation Loss: 0.1523\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [17/50]\n",
      "Training Loss: 0.1316\n",
      "Validation Loss: 0.1522\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [18/50]\n",
      "Training Loss: 0.1312\n",
      "Validation Loss: 0.1521\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [19/50]\n",
      "Training Loss: 0.1315\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 80.42%\n",
      "Precision: 0.8261\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7308\n",
      "Validation loss improved, model saved.\n",
      "Epoch [20/50]\n",
      "Training Loss: 0.1312\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [21/50]\n",
      "Training Loss: 0.1313\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [22/50]\n",
      "Training Loss: 0.1315\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [23/50]\n",
      "Training Loss: 0.1311\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [24/50]\n",
      "Training Loss: 0.1310\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [25/50]\n",
      "Training Loss: 0.1309\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [26/50]\n",
      "Training Loss: 0.1307\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [27/50]\n",
      "Training Loss: 0.1308\n",
      "Validation Loss: 0.1520\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [28/50]\n",
      "Training Loss: 0.1317\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [29/50]\n",
      "Training Loss: 0.1317\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [30/50]\n",
      "Training Loss: 0.1310\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [31/50]\n",
      "Training Loss: 0.1313\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [32/50]\n",
      "Training Loss: 0.1314\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [33/50]\n",
      "Training Loss: 0.1313\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [34/50]\n",
      "Training Loss: 0.1310\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [35/50]\n",
      "Training Loss: 0.1311\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [36/50]\n",
      "Training Loss: 0.1308\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [37/50]\n",
      "Training Loss: 0.1306\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [38/50]\n",
      "Training Loss: 0.1314\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [39/50]\n",
      "Training Loss: 0.1313\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [40/50]\n",
      "Training Loss: 0.1317\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [41/50]\n",
      "Training Loss: 0.1316\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [42/50]\n",
      "Training Loss: 0.1318\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [43/50]\n",
      "Training Loss: 0.1320\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [44/50]\n",
      "Training Loss: 0.1311\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [45/50]\n",
      "Training Loss: 0.1312\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [46/50]\n",
      "Training Loss: 0.1305\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [47/50]\n",
      "Training Loss: 0.1316\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [48/50]\n",
      "Training Loss: 0.1310\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [49/50]\n",
      "Training Loss: 0.1313\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Epoch [50/50]\n",
      "Training Loss: 0.1310\n",
      "Validation Loss: 0.1519\n",
      "Validation Accuracy: 81.12%\n",
      "Precision: 0.8444\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7379\n",
      "Validation loss improved, model saved.\n",
      "Validation Loss: 0.1519, Accuracy: 81.12%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using MSELoss for training the model on the Titanic dataset with improvements\n",
    "\n",
    "\n",
    "mse_model = SimpleMLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    last_layer_activation_fn=nn.Sigmoid  # Added Sigmoid activation function\n",
    ")\n",
    "\n",
    "# Define the loss function using Mean Squared Error (MSELoss)\n",
    "mse_loss_function = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer with a learning rate of 0.001)\n",
    "mse_optimizer = torch.optim.Adam(mse_model.parameters(), lr=0.001)\n",
    "\n",
    "# Define a learning rate scheduler to adjust the learning rate during training\n",
    "mse_scheduler = StepLR(mse_optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Instantiate the SimpleMLPTrainer with the model, loss function, optimizer, and scheduler\n",
    "mse_trainer = SimpleMLPTrainer(\n",
    "    model=mse_model,\n",
    "    criterion=mse_loss_function,\n",
    "    optimizer=mse_optimizer,\n",
    "    scheduler=mse_scheduler,\n",
    "    save_model=True,                    # Save the model when validation loss improves\n",
    "    checkpoint_path='best_mse_model.pth'  # Path to save the best model\n",
    ")\n",
    "\n",
    "# Set the number of epochs for training\n",
    "num_epochs = 50\n",
    "\n",
    "# Implement early stopping parameters\n",
    "early_stopping_patience = 5  # Stop training if validation loss doesn't improve for 5 consecutive epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Lists to store training and validation metrics\n",
    "mse_training_losses = []\n",
    "mse_validation_losses = []\n",
    "mse_validation_accuracies = []\n",
    "mse_validation_precisions = []\n",
    "mse_validation_recalls = []\n",
    "mse_validation_f1s = []\n",
    "\n",
    "# Training loop with early stopping and metric tracking\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    mse_model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_inputs, batch_targets in train_loader:\n",
    "        mse_optimizer.zero_grad()\n",
    "        predictions = mse_model(batch_inputs)\n",
    "        loss = mse_loss_function(predictions, batch_targets)\n",
    "        loss.backward()\n",
    "        mse_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_training_loss = running_loss / len(train_loader)\n",
    "    mse_training_losses.append(avg_training_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    mse_model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_targets in val_loader:\n",
    "            predictions = mse_model(batch_inputs)\n",
    "            loss = mse_loss_function(predictions, batch_targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Since outputs are already probabilities, use them directly\n",
    "            predicted_labels = (predictions >= 0.5).float().squeeze()\n",
    "            all_predictions.extend(predicted_labels.cpu().numpy())\n",
    "            all_targets.extend(batch_targets.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    mse_validation_losses.append(avg_val_loss)\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    accuracy = (np.array(all_predictions) == np.array(all_targets).flatten()).mean() * 100\n",
    "    precision = precision_score(all_targets, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_targets, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_targets, all_predictions, zero_division=0)\n",
    "    mse_validation_accuracies.append(accuracy)\n",
    "    mse_validation_precisions.append(precision)\n",
    "    mse_validation_recalls.append(recall)\n",
    "    mse_validation_f1s.append(f1)\n",
    "\n",
    "    # Print metrics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Training Loss: {avg_training_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Check for improvement\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # Save the best model\n",
    "        torch.save(mse_model.state_dict(), 'best_mse_model.pth')\n",
    "        print(\"Validation loss improved, model saved.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"No improvement in validation loss for {epochs_without_improvement} epochs.\")\n",
    "\n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "    # Step the scheduler\n",
    "    mse_scheduler.step()\n",
    "\n",
    "# Load the best model before evaluation\n",
    "mse_model.load_state_dict(torch.load('best_mse_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "final_val_loss, final_val_accuracy = mse_trainer.evaluate(val_loader)\n",
    "\n",
    "# # Plot training and validation losses\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(mse_training_losses)+1), mse_training_losses, label='Training Loss')\n",
    "# plt.plot(range(1, len(mse_validation_losses)+1), mse_validation_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss over Epochs (MSELoss)')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot validation accuracy, precision, recall, and F1 score\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(mse_validation_accuracies)+1), mse_validation_accuracies, label='Accuracy')\n",
    "# plt.plot(range(1, len(mse_validation_precisions)+1), mse_validation_precisions, label='Precision')\n",
    "# plt.plot(range(1, len(mse_validation_recalls)+1), mse_validation_recalls, label='Recall')\n",
    "# plt.plot(range(1, len(mse_validation_f1s)+1), mse_validation_f1s, label='F1 Score')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Metric')\n",
    "# plt.title('Validation Metrics over Epochs (MSELoss)')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NLLLoss (`torch.nn.NLLLoss`)\n",
    "- **Description:** Negative Log-Likelihood Loss measures the likelihood of the target class under the predicted probability distribution.\n",
    "- **Use Case:** Typically used in multi-class classification tasks, especially when combined with `log_softmax` activation.\n",
    "\n",
    "Here is the mathematical formulation of NLLLoss:\n",
    "\\begin{equation}\n",
    "\\text{NLLLoss} = -\\frac{1}{n} \\sum_{i=1}^{n} \\log(y_{i})\n",
    "\\end{equation}\n",
    "\n",
    "I hope you note the logarithm in the formula. It's important! \n",
    "\n",
    "Why?\n",
    "\n",
    "\n",
    "In this part, run your training with Relu at last layer. <span style=\"color:red; font-weight: bold;\">Discuss </span> and explain the difference between the results of the two models. Find a proper solution to the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Epoch 1/20: 100%|██████████| 18/18 [00:00<00:00, 340.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: -0.8111\n",
      "Validation Loss: -1.1250, Accuracy: 47.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 18/18 [00:00<00:00, 425.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: -1.2510\n",
      "Validation Loss: -1.6599, Accuracy: 48.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 18/18 [00:00<00:00, 644.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: -1.8502\n",
      "Validation Loss: -2.3210, Accuracy: 47.55%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 18/18 [00:00<00:00, 608.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: -2.5660\n",
      "Validation Loss: -3.0528, Accuracy: 53.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 18/18 [00:00<00:00, 874.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: -3.3508\n",
      "Validation Loss: -3.9134, Accuracy: 55.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 18/18 [00:00<00:00, 449.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: -4.3061\n",
      "Validation Loss: -4.9263, Accuracy: 56.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 18/18 [00:00<00:00, 345.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: -5.4499\n",
      "Validation Loss: -6.1513, Accuracy: 59.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 18/18 [00:00<00:00, 355.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: -6.7668\n",
      "Validation Loss: -7.6254, Accuracy: 65.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 18/18 [00:00<00:00, 157.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: -8.4183\n",
      "Validation Loss: -9.3493, Accuracy: 65.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 18/18 [00:00<00:00, 374.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: -10.3022\n",
      "Validation Loss: -11.4378, Accuracy: 67.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 18/18 [00:00<00:00, 432.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: -12.5406\n",
      "Validation Loss: -13.8604, Accuracy: 69.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 18/18 [00:00<00:00, 428.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: -15.1631\n",
      "Validation Loss: -16.6393, Accuracy: 70.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 18/18 [00:00<00:00, 322.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: -18.2372\n",
      "Validation Loss: -19.9133, Accuracy: 72.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 18/18 [00:00<00:00, 374.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: -21.8062\n",
      "Validation Loss: -23.7011, Accuracy: 72.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 18/18 [00:00<00:00, 406.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: -25.9689\n",
      "Validation Loss: -28.0982, Accuracy: 72.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 18/18 [00:00<00:00, 475.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: -30.7140\n",
      "Validation Loss: -33.2038, Accuracy: 72.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 18/18 [00:00<00:00, 443.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: -36.2996\n",
      "Validation Loss: -38.9901, Accuracy: 71.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 18/18 [00:00<00:00, 432.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: -42.6624\n",
      "Validation Loss: -45.5577, Accuracy: 67.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 18/18 [00:00<00:00, 589.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: -49.8115\n",
      "Validation Loss: -53.0735, Accuracy: 49.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 18/18 [00:00<00:00, 479.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: -58.0678\n",
      "Validation Loss: -61.4787, Accuracy: 48.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 18/18 [00:00<00:00, 120.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.6199\n",
      "Validation Loss: 0.6391, Accuracy: 69.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 18/18 [00:00<00:00, 361.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.5367\n",
      "Validation Loss: 0.5776, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 18/18 [00:00<00:00, 415.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.4946\n",
      "Validation Loss: 0.5509, Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 18/18 [00:00<00:00, 330.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.4745\n",
      "Validation Loss: 0.5440, Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 18/18 [00:00<00:00, 403.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.4644\n",
      "Validation Loss: 0.5332, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 18/18 [00:00<00:00, 381.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.4540\n",
      "Validation Loss: 0.5257, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 18/18 [00:00<00:00, 385.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.4512\n",
      "Validation Loss: 0.5224, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 18/18 [00:00<00:00, 389.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.4446\n",
      "Validation Loss: 0.5152, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 18/18 [00:00<00:00, 620.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.4397\n",
      "Validation Loss: 0.5107, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 18/18 [00:00<00:00, 482.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.4372\n",
      "Validation Loss: 0.5094, Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 18/18 [00:00<00:00, 693.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.4341\n",
      "Validation Loss: 0.5031, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 18/18 [00:00<00:00, 361.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.4309\n",
      "Validation Loss: 0.5000, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 18/18 [00:00<00:00, 199.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.4267\n",
      "Validation Loss: 0.5036, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 18/18 [00:00<00:00, 368.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.4258\n",
      "Validation Loss: 0.4973, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 18/18 [00:00<00:00, 422.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.4230\n",
      "Validation Loss: 0.4941, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 18/18 [00:00<00:00, 505.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.4209\n",
      "Validation Loss: 0.4934, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 18/18 [00:00<00:00, 288.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.4195\n",
      "Validation Loss: 0.4944, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 18/18 [00:00<00:00, 403.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.4171\n",
      "Validation Loss: 0.4955, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 18/18 [00:00<00:00, 352.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.4147\n",
      "Validation Loss: 0.4974, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 18/18 [00:00<00:00, 366.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.4161\n",
      "Validation Loss: 0.4982, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Data loading and preprocessing\n",
    "train_url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "response = requests.get(train_url, verify=False)\n",
    "titanic_data = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "# Select relevant features and drop missing values\n",
    "titanic_data = titanic_data[['Pclass', 'Sex', 'Age', 'Fare', 'Survived']].dropna()\n",
    "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Extract features and labels\n",
    "feature_array = titanic_data[['Pclass', 'Sex', 'Age', 'Fare']].values\n",
    "label_array = titanic_data['Survived'].values\n",
    "\n",
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_feature_array = scaler.fit_transform(feature_array)\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "feature_tensor = torch.tensor(scaled_feature_array, dtype=torch.float32)\n",
    "# For NLLLoss, labels should be LongTensors with class indices\n",
    "label_tensor = torch.tensor(label_array, dtype=torch.long)\n",
    "\n",
    "# Create a TensorDataset from tensors\n",
    "titanic_dataset = TensorDataset(feature_tensor, label_tensor)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset_size = int(0.8 * len(titanic_dataset))\n",
    "validation_dataset_size = len(titanic_dataset) - train_dataset_size\n",
    "training_dataset, validation_dataset = random_split(\n",
    "    titanic_dataset, [train_dataset_size, validation_dataset_size]\n",
    ")\n",
    "\n",
    "# Create DataLoaders for training and validation\n",
    "training_loader = DataLoader(\n",
    "    training_dataset, batch_size=32, shuffle=True\n",
    ")\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset, batch_size=32, shuffle=False\n",
    ")\n",
    "\n",
    "# Define model parameters\n",
    "input_dimension = feature_array.shape[1]  # Number of input features from the dataset\n",
    "hidden_dimension = 16                     # Number of neurons in each hidden layer\n",
    "output_dimension = 2                      # Output dimension for multi-class classification (number of classes)\n",
    "number_of_hidden_layers = 2               # Total number of hidden layers in the model\n",
    "num_epochs = 20                           # Number of epochs for training\n",
    "\n",
    "# Model with ReLU as the last layer activation function\n",
    "nll_relu_model = SimpleMLP(\n",
    "    input_dim=input_dimension,\n",
    "    hidden_dim=hidden_dimension,\n",
    "    output_dim=output_dimension,\n",
    "    num_hidden_layers=number_of_hidden_layers,\n",
    "    last_layer_activation_fn=nn.ReLU  # Using ReLU as the last activation function\n",
    ")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "nll_loss_function = nn.NLLLoss()\n",
    "nll_optimizer = torch.optim.Adam(nll_relu_model.parameters(), lr=0.001)\n",
    "\n",
    "# Instantiate the SimpleMLPTrainer with the model, loss function, and optimizer\n",
    "nll_trainer = SimpleMLPTrainer(\n",
    "    model=nll_relu_model,\n",
    "    criterion=nll_loss_function,\n",
    "    optimizer=nll_optimizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    nll_training_losses = nll_trainer.train(\n",
    "        train_loader=training_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        val_loader=validation_loader\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training: {e}\")\n",
    "\n",
    "# Proper solution: Adjust the last activation function to LogSoftmax\n",
    "# This ensures that the outputs are log-probabilities as required by NLLLoss\n",
    "nll_logsoftmax_model = SimpleMLP(\n",
    "    input_dim=input_dimension,\n",
    "    hidden_dim=hidden_dimension,\n",
    "    output_dim=output_dimension,\n",
    "    num_hidden_layers=number_of_hidden_layers,\n",
    "    last_layer_activation_fn=lambda: nn.LogSoftmax(dim=1)  # Using LogSoftmax as the last activation function\n",
    ")\n",
    "\n",
    "# Redefine the loss function and optimizer\n",
    "nll_logsoftmax_optimizer = torch.optim.Adam(nll_logsoftmax_model.parameters(), lr=0.001)\n",
    "\n",
    "# Instantiate the trainer with the corrected model\n",
    "nll_logsoftmax_trainer = SimpleMLPTrainer(\n",
    "    model=nll_logsoftmax_model,\n",
    "    criterion=nll_loss_function,\n",
    "    optimizer=nll_logsoftmax_optimizer\n",
    ")\n",
    "\n",
    "# Train the corrected model\n",
    "nll_logsoftmax_training_losses = nll_logsoftmax_trainer.train(\n",
    "    train_loader=training_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    val_loader=validation_loader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your reason for your choice:**\n",
    "\n",
    "**Difference between the two models:**\n",
    "\n",
    "- **Model with ReLU Activation in the Last Layer:**\n",
    "\n",
    "  - **Outputs:** Using `nn.ReLU` as the last activation function produces non-negative outputs that are not normalized and do not represent log-probabilities.\n",
    "  - **Loss Behavior:** The training loss becomes increasingly negative over epochs (as seen in the results), which is not typical or meaningful for a loss function. Negative loss values indicate that the loss computation is not functioning as intended.\n",
    "  - **Model Performance:** The accuracy fluctuates and eventually decreases, suggesting that the model is not learning effectively.\n",
    "\n",
    "- **Model with LogSoftmax Activation in the Last Layer:**\n",
    "\n",
    "  - **Outputs:** Using `nn.LogSoftmax(dim=1)` ensures that the model outputs are log-probabilities. This activation function applies softmax to produce probabilities that sum to one and then takes the logarithm.\n",
    "  - **Loss Behavior:** The training loss decreases over epochs, converging towards a minimum value. This is expected behavior for a properly functioning loss function.\n",
    "  - **Model Performance:** The validation accuracy improves and stabilizes at a higher percentage compared to the model with ReLU, indicating effective learning.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "- **Importance of the Logarithm in NLLLoss:**\n",
    "\n",
    "  - The `nn.NLLLoss` function computes the negative log-likelihood loss, which requires the input to be log-probabilities of the classes.\n",
    "  - The mathematical formulation is:\n",
    "\n",
    "    \\[\n",
    "    \\text{NLLLoss} = -\\frac{1}{n} \\sum_{i=1}^{n} \\log(p_i)\n",
    "    \\]\n",
    "\n",
    "    where \\( p_i \\) is the predicted probability of the correct class for sample \\( i \\).\n",
    "\n",
    "- **Why ReLU is Inappropriate:**\n",
    "\n",
    "  - **ReLU Outputs:** The ReLU activation function outputs values in the range \\([0, \\infty)\\), which are not log-probabilities.\n",
    "  - **Mismatch with NLLLoss:** Feeding these non-logarithmic, non-normalized outputs into `nn.NLLLoss` leads to incorrect loss calculations and ineffective training.\n",
    "  - **Resulting Issues:** The loss becomes negative and decreases indefinitely, and the model fails to learn meaningful patterns from the data.\n",
    "\n",
    "- **Why LogSoftmax is Appropriate:**\n",
    "\n",
    "  - **LogSoftmax Outputs:** The `nn.LogSoftmax(dim=1)` activation function produces outputs that are log-probabilities, ensuring that after exponentiation, the probabilities sum to one.\n",
    "  - **Compatibility with NLLLoss:** Since `nn.NLLLoss` expects log-probabilities, using `nn.LogSoftmax` aligns the model's outputs with the loss function's requirements.\n",
    "  - **Effective Training:** This leads to meaningful loss values that decrease over time, allowing the model to learn effectively and improve accuracy.\n",
    "\n",
    "**Proper Solution:**\n",
    "\n",
    "- **Adjust the Last Activation Function:**\n",
    "\n",
    "  - Replace `nn.ReLU` with `nn.LogSoftmax(dim=1)` in the last layer of the model.\n",
    "  - This ensures that the outputs are suitable for `nn.NLLLoss`.\n",
    "\n",
    "- **Alternative Approach:**\n",
    "\n",
    "  - Use `nn.CrossEntropyLoss` instead of `nn.NLLLoss` and remove the last activation function.\n",
    "  - `nn.CrossEntropyLoss` combines `nn.LogSoftmax` and `nn.NLLLoss` internally and works directly with raw logits.\n",
    "\n",
    "\n",
    "\n",
    "I chose to adjust the last activation function to `nn.LogSoftmax(dim=1)` because it produces log-probabilities required by `nn.NLLLoss`. Using `nn.ReLU` was inappropriate since it does not output log-probabilities, leading to incorrect loss calculations and ineffective training.\n",
    "\n",
    "By ensuring that the model's outputs align with the loss function's expectations, the training process becomes effective, as evidenced by the decreasing loss and increasing accuracy in the results. This adjustment is crucial for the model to learn meaningful patterns and make accurate predictions.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "- The mismatch between the activation function and the loss function can severely impact model training.\n",
    "- Using `nn.LogSoftmax` with `nn.NLLLoss` ensures compatibility and effective learning.\n",
    "- Always ensure that the outputs of your model are appropriate for the loss function being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. CrossEntropyLoss (`torch.nn.CrossEntropyLoss`)\n",
    "- **Description:** Combines `LogSoftmax` and `NLLLoss` in one single class. It computes the cross-entropy loss between the target and the output logits.\n",
    "- **Use Case:** Widely used for multi-class classification problems.\n",
    "\n",
    "The mathematical formulation of CrossEntropyLoss is as follows:\n",
    "\\begin{equation}\n",
    "  \\text{CrossEntropy}(y, \\hat{y}) = - \\sum_{i=1}^{C} y_i \\log\\left(\\frac{e^{\\hat{y}_i}}{\\sum_{j=1}^{C} e^{\\hat{y}_j}}\\right)\n",
    "\\end{equation}\n",
    "  where:\n",
    "  - \\( C \\) is the number of classes,\n",
    "  - \\( y_i \\) is a one-hot encoded target vector (or a scalar class label),\n",
    "  - \\( \\hat{y}_i \\) represents the logits (unnormalized model outputs) for each class.\n",
    "  \n",
    "  In practice, `torch.nn.CrossEntropyLoss` expects raw logits as input and internally applies the softmax function to convert the logits into probabilities, followed by the negative log-likelihood computation.\n",
    "\n",
    "- **Background:** Cross-entropy measures the difference between the true distribution \\( y \\) and the predicted distribution \\( \\hat{y} \\). The function minimizes the negative log-probability assigned to the correct class, effectively penalizing predictions that deviate from the true class, making it a standard choice for classification tasks in deep learning.\n",
    "\n",
    "Now, let's implement a class called `SimpleMLP_Loss` that has the following architecture:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Epoch 1/50: 100%|██████████| 18/18 [00:00<00:00, 381.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "Training Loss: 0.9784\n",
      "Validation Loss: 0.7404\n",
      "Validation Accuracy: 46.85%\n",
      "Precision: 0.3594\n",
      "Recall: 0.3966\n",
      "F1 Score: 0.3770\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 18/18 [00:00<00:00, 690.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50]\n",
      "Training Loss: 0.7031\n",
      "Validation Loss: 0.5735\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.7121\n",
      "Recall: 0.8103\n",
      "F1 Score: 0.7581\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 18/18 [00:00<00:00, 418.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50]\n",
      "Training Loss: 0.5665\n",
      "Validation Loss: 0.5104\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.7500\n",
      "Recall: 0.7241\n",
      "F1 Score: 0.7368\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 18/18 [00:00<00:00, 449.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50]\n",
      "Training Loss: 0.5068\n",
      "Validation Loss: 0.4776\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.8043\n",
      "Recall: 0.6379\n",
      "F1 Score: 0.7115\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 18/18 [00:00<00:00, 443.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50]\n",
      "Training Loss: 0.4812\n",
      "Validation Loss: 0.4678\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.8182\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.7059\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 18/18 [00:00<00:00, 167.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50]\n",
      "Training Loss: 0.4708\n",
      "Validation Loss: 0.4655\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7660\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.6857\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 18/18 [00:00<00:00, 589.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50]\n",
      "Training Loss: 0.4649\n",
      "Validation Loss: 0.4634\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7273\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7080\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 18/18 [00:00<00:00, 749.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50]\n",
      "Training Loss: 0.4592\n",
      "Validation Loss: 0.4616\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7273\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7080\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 18/18 [00:00<00:00, 443.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50]\n",
      "Training Loss: 0.4562\n",
      "Validation Loss: 0.4611\n",
      "Validation Accuracy: 76.22%\n",
      "Precision: 0.7143\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7018\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 18/18 [00:00<00:00, 781.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50]\n",
      "Training Loss: 0.4517\n",
      "Validation Loss: 0.4603\n",
      "Validation Accuracy: 76.22%\n",
      "Precision: 0.7143\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7018\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 18/18 [00:00<00:00, 477.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50]\n",
      "Training Loss: 0.4505\n",
      "Validation Loss: 0.4602\n",
      "Validation Accuracy: 76.22%\n",
      "Precision: 0.7143\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7018\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 18/18 [00:00<00:00, 460.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50]\n",
      "Training Loss: 0.4497\n",
      "Validation Loss: 0.4596\n",
      "Validation Accuracy: 76.22%\n",
      "Precision: 0.7143\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 18/18 [00:00<00:00, 428.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50]\n",
      "Training Loss: 0.4465\n",
      "Validation Loss: 0.4557\n",
      "Validation Accuracy: 74.83%\n",
      "Precision: 0.7200\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.6667\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 18/18 [00:00<00:00, 403.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50]\n",
      "Training Loss: 0.4431\n",
      "Validation Loss: 0.4548\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7273\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7080\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 18/18 [00:00<00:00, 473.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50]\n",
      "Training Loss: 0.4433\n",
      "Validation Loss: 0.4537\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7358\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7027\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 18/18 [00:00<00:00, 409.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50]\n",
      "Training Loss: 0.4395\n",
      "Validation Loss: 0.4548\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7321\n",
      "Recall: 0.7069\n",
      "F1 Score: 0.7193\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 18/18 [00:00<00:00, 155.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50]\n",
      "Training Loss: 0.4385\n",
      "Validation Loss: 0.4534\n",
      "Validation Accuracy: 76.22%\n",
      "Precision: 0.7400\n",
      "Recall: 0.6379\n",
      "F1 Score: 0.6852\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 18/18 [00:00<00:00, 434.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50]\n",
      "Training Loss: 0.4348\n",
      "Validation Loss: 0.4538\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7321\n",
      "Recall: 0.7069\n",
      "F1 Score: 0.7193\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 18/18 [00:00<00:00, 499.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50]\n",
      "Training Loss: 0.4364\n",
      "Validation Loss: 0.4531\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7321\n",
      "Recall: 0.7069\n",
      "F1 Score: 0.7193\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 18/18 [00:00<00:00, 378.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50]\n",
      "Training Loss: 0.4318\n",
      "Validation Loss: 0.4498\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7358\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7027\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 18/18 [00:00<00:00, 609.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50]\n",
      "Training Loss: 0.4296\n",
      "Validation Loss: 0.4508\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7321\n",
      "Recall: 0.7069\n",
      "F1 Score: 0.7193\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 18/18 [00:00<00:00, 734.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50]\n",
      "Training Loss: 0.4288\n",
      "Validation Loss: 0.4515\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.7455\n",
      "Recall: 0.7069\n",
      "F1 Score: 0.7257\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 18/18 [00:00<00:00, 521.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50]\n",
      "Training Loss: 0.4269\n",
      "Validation Loss: 0.4485\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.7547\n",
      "Recall: 0.6897\n",
      "F1 Score: 0.7207\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 18/18 [00:00<00:00, 422.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50]\n",
      "Training Loss: 0.4251\n",
      "Validation Loss: 0.4477\n",
      "Validation Accuracy: 76.22%\n",
      "Precision: 0.7609\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6731\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 18/18 [00:00<00:00, 473.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50]\n",
      "Training Loss: 0.4252\n",
      "Validation Loss: 0.4472\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7500\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7091\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 18/18 [00:00<00:00, 491.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50]\n",
      "Training Loss: 0.4219\n",
      "Validation Loss: 0.4458\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7708\n",
      "Recall: 0.6379\n",
      "F1 Score: 0.6981\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 18/18 [00:00<00:00, 486.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50]\n",
      "Training Loss: 0.4234\n",
      "Validation Loss: 0.4478\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7600\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7037\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 18/18 [00:00<00:00, 457.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50]\n",
      "Training Loss: 0.4185\n",
      "Validation Loss: 0.4473\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7500\n",
      "Recall: 0.6724\n",
      "F1 Score: 0.7091\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 18/18 [00:00<00:00, 292.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50]\n",
      "Training Loss: 0.4189\n",
      "Validation Loss: 0.4446\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7778\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6796\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 18/18 [00:00<00:00, 350.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Loss: 0.4171\n",
      "Validation Loss: 0.4482\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.7455\n",
      "Recall: 0.7069\n",
      "F1 Score: 0.7257\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 18/18 [00:00<00:00, 438.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50]\n",
      "Training Loss: 0.4149\n",
      "Validation Loss: 0.4453\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.7755\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7103\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 18/18 [00:00<00:00, 466.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50]\n",
      "Training Loss: 0.4160\n",
      "Validation Loss: 0.4452\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7826\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.6923\n",
      "No improvement in validation loss for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 18/18 [00:00<00:00, 368.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50]\n",
      "Training Loss: 0.4126\n",
      "Validation Loss: 0.4444\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7600\n",
      "Recall: 0.6552\n",
      "F1 Score: 0.7037\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 18/18 [00:00<00:00, 536.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50]\n",
      "Training Loss: 0.4136\n",
      "Validation Loss: 0.4426\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7955\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6863\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 18/18 [00:00<00:00, 398.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50]\n",
      "Training Loss: 0.4139\n",
      "Validation Loss: 0.4436\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7708\n",
      "Recall: 0.6379\n",
      "F1 Score: 0.6981\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 18/18 [00:00<00:00, 516.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50]\n",
      "Training Loss: 0.4120\n",
      "Validation Loss: 0.4424\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.8095\n",
      "Recall: 0.5862\n",
      "F1 Score: 0.6800\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 18/18 [00:00<00:00, 703.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50]\n",
      "Training Loss: 0.4106\n",
      "Validation Loss: 0.4426\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7708\n",
      "Recall: 0.6379\n",
      "F1 Score: 0.6981\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 18/18 [00:00<00:00, 589.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50]\n",
      "Training Loss: 0.4109\n",
      "Validation Loss: 0.4425\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.8140\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6931\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 18/18 [00:00<00:00, 390.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50]\n",
      "Training Loss: 0.4104\n",
      "Validation Loss: 0.4406\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.8140\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6931\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 18/18 [00:00<00:00, 449.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50]\n",
      "Training Loss: 0.4090\n",
      "Validation Loss: 0.4424\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7826\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.6923\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 18/18 [00:00<00:00, 408.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50]\n",
      "Training Loss: 0.4117\n",
      "Validation Loss: 0.4417\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.8140\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6931\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 18/18 [00:00<00:00, 342.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50]\n",
      "Training Loss: 0.4077\n",
      "Validation Loss: 0.4424\n",
      "Validation Accuracy: 76.92%\n",
      "Precision: 0.7551\n",
      "Recall: 0.6379\n",
      "F1 Score: 0.6916\n",
      "No improvement in validation loss for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 18/18 [00:00<00:00, 422.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50]\n",
      "Training Loss: 0.4081\n",
      "Validation Loss: 0.4417\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.8140\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6931\n",
      "No improvement in validation loss for 4 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 18/18 [00:00<00:00, 618.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50]\n",
      "Training Loss: 0.4067\n",
      "Validation Loss: 0.4405\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.8140\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.6931\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 18/18 [00:00<00:00, 461.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50]\n",
      "Training Loss: 0.4085\n",
      "Validation Loss: 0.4385\n",
      "Validation Accuracy: 78.32%\n",
      "Precision: 0.8293\n",
      "Recall: 0.5862\n",
      "F1 Score: 0.6869\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 18/18 [00:00<00:00, 418.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50]\n",
      "Training Loss: 0.4069\n",
      "Validation Loss: 0.4429\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.7826\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.6923\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 18/18 [00:00<00:00, 448.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50]\n",
      "Training Loss: 0.4072\n",
      "Validation Loss: 0.4393\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.8333\n",
      "Recall: 0.6034\n",
      "F1 Score: 0.7000\n",
      "No improvement in validation loss for 2 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 18/18 [00:00<00:00, 449.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50]\n",
      "Training Loss: 0.4040\n",
      "Validation Loss: 0.4409\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.8182\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.7059\n",
      "No improvement in validation loss for 3 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 18/18 [00:00<00:00, 570.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50]\n",
      "Training Loss: 0.4062\n",
      "Validation Loss: 0.4378\n",
      "Validation Accuracy: 77.62%\n",
      "Precision: 0.8095\n",
      "Recall: 0.5862\n",
      "F1 Score: 0.6800\n",
      "Validation loss improved, model saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 18/18 [00:00<00:00, 388.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50]\n",
      "Training Loss: 0.4036\n",
      "Validation Loss: 0.4390\n",
      "Validation Accuracy: 79.02%\n",
      "Precision: 0.8182\n",
      "Recall: 0.6207\n",
      "F1 Score: 0.7059\n",
      "No improvement in validation loss for 1 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4378, Accuracy: 77.62%\n",
      "Final Validation Loss: 0.4378, Accuracy: 77.62%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate the SimpleMLP model without an activation function in the last layer\n",
    "cross_entropy_model = SimpleMLP(\n",
    "    input_dim=input_size,\n",
    "    hidden_dim=hidden_size,\n",
    "    output_dim=output_size,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    last_layer_activation_fn=None  # No activation function in the last layer for CrossEntropyLoss\n",
    ")\n",
    "\n",
    "# Define the loss function using CrossEntropyLoss\n",
    "cross_entropy_loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer with a learning rate of 0.001)\n",
    "cross_entropy_optimizer = torch.optim.Adam(cross_entropy_model.parameters(), lr=0.001)\n",
    "\n",
    "# Instantiate the SimpleMLPTrainer with the model, loss function, and optimizer\n",
    "cross_entropy_trainer = SimpleMLPTrainer(\n",
    "    model=cross_entropy_model,\n",
    "    criterion=cross_entropy_loss_fn,\n",
    "    optimizer=cross_entropy_optimizer\n",
    ")\n",
    "\n",
    "# Implement early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "early_stopping_patience = 5\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "# Lists to store training and validation metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_precisions = []\n",
    "val_recalls = []\n",
    "val_f1_scores = []\n",
    "\n",
    "# Training loop with early stopping and metric tracking\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    cross_entropy_model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_inputs, batch_labels in tqdm(\n",
    "        train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"\n",
    "    ):\n",
    "        cross_entropy_optimizer.zero_grad()\n",
    "        outputs = cross_entropy_model(batch_inputs)\n",
    "        loss = cross_entropy_loss_fn(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        cross_entropy_optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    avg_train_loss = running_loss / len(train_dataloader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    cross_entropy_model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch_inputs, batch_labels in val_dataloader:\n",
    "            outputs = cross_entropy_model(batch_inputs)\n",
    "            loss = cross_entropy_loss_fn(outputs, batch_labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Get predicted class labels\n",
    "            _, predicted_classes = torch.max(outputs, 1)\n",
    "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    \n",
    "    # Calculate validation metrics\n",
    "    accuracy = (np.array(all_predictions) == np.array(all_labels)).mean() * 100\n",
    "    precision = precision_score(all_labels, all_predictions, zero_division=0)\n",
    "    recall = recall_score(all_labels, all_predictions, zero_division=0)\n",
    "    f1 = f1_score(all_labels, all_predictions, zero_division=0)\n",
    "    val_accuracies.append(accuracy)\n",
    "    val_precisions.append(precision)\n",
    "    val_recalls.append(recall)\n",
    "    val_f1_scores.append(f1)\n",
    "    \n",
    "    # Print epoch metrics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Training Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Check for improvement\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        # Save the best model\n",
    "        torch.save(cross_entropy_model.state_dict(), 'best_cross_entropy_model.pth')\n",
    "        print(\"Validation loss improved, model saved.\")\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "        print(f\"No improvement in validation loss for {epochs_without_improvement} epochs.\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "# Load the best model before evaluation\n",
    "cross_entropy_model.load_state_dict(torch.load('best_cross_entropy_model.pth'))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "final_val_loss, final_val_accuracy = cross_entropy_trainer.evaluate(val_dataloader)\n",
    "print(f\"Final Validation Loss: {final_val_loss:.4f}, Accuracy: {final_val_accuracy:.2f}%\")\n",
    "\n",
    "# # Plot training and validation losses\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(train_losses)+1), train_losses, label='Training Loss')\n",
    "# plt.plot(range(1, len(val_losses)+1), val_losses, label='Validation Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training and Validation Loss over Epochs (CrossEntropyLoss)')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # Plot validation accuracy, precision, recall, and F1 score\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(range(1, len(val_accuracies)+1), val_accuracies, label='Accuracy')\n",
    "# plt.plot(range(1, len(val_precisions)+1), val_precisions, label='Precision')\n",
    "# plt.plot(range(1, len(val_recalls)+1), val_recalls, label='Recall')\n",
    "# plt.plot(range(1, len(val_f1_scores)+1), val_f1_scores, label='F1 Score')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Metric')\n",
    "# plt.title('Validation Metrics over Epochs (CrossEntropyLoss)')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 5. KLDivLoss (`torch.nn.KLDivLoss`)\n",
    "- **Description:** Kullback-Leibler Divergence Loss measures how one probability distribution diverges from a second, reference distribution. Unlike other loss functions that focus on classification, KL divergence specifically compares the relative entropy between two distributions. It quantifies the information loss when using the predicted distribution to approximate the true distribution. \n",
    "\n",
    "- **Mathematical Function:**\n",
    "\\begin{equation}\n",
    "  \\text{KL}(P \\parallel Q) = \\sum_{i=1}^{C} P(i) \\left( \\log P(i) - \\log Q(i) \\right)\n",
    "\\end{equation}\n",
    "  where:\n",
    "  - \\( P \\) is the target (true) probability distribution,\n",
    "  - \\( Q \\) is the predicted distribution (often the output of `log_softmax`),\n",
    "  - \\( C \\) is the number of classes.\n",
    "\n",
    "  KL divergence is always non-negative, and it equals zero if the two distributions are identical. The loss function expects the model's output to be in the form of log-probabilities (using `log_softmax`) and compares this against a target probability distribution, which is typically a normalized distribution (using softmax).\n",
    "\n",
    "- **Use Case:** KLDivLoss is frequently used in:\n",
    "  - **Variational Autoencoders (VAEs):** In VAEs, KL divergence is used to measure how much the learned latent space distribution deviates from a prior distribution (often Gaussian).\n",
    "  - **Knowledge Distillation:** In teacher-student models, KL divergence is used to transfer the \"soft\" knowledge from a teacher model to a student model by comparing their output probability distributions.\n",
    "  - **Reinforcement Learning:** It can be used to update policies while minimizing the divergence from a previous policy.\n",
    "\n",
    "- **Background:** Kullback-Leibler divergence, a core concept in information theory, measures the inefficiency of assuming the predicted distribution \\( Q \\) when the true distribution is \\( P \\). It is asymmetric, meaning that \\( KL(P \\parallel Q) \\neq KL(Q \\parallel P) \\), so the direction of the comparison matters.\n",
    "\n",
    "Again, in this part, run your training with Relu at last layer. <span style=\"color:red; font-weight: bold;\">Discuss </span> and explain the difference between the results of the two models. Find a proper solution to the problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'raw.githubusercontent.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "Epoch 1/20: 100%|██████████| 18/18 [00:00<00:00, 521.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: -0.4867\n",
      "Validation Loss: -0.5903, Accuracy: 34.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 18/18 [00:00<00:00, 551.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: -0.9431\n",
      "Validation Loss: -1.0901, Accuracy: 35.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 18/18 [00:00<00:00, 392.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: -1.5156\n",
      "Validation Loss: -1.6582, Accuracy: 55.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 18/18 [00:00<00:00, 328.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: -2.1626\n",
      "Validation Loss: -2.3034, Accuracy: 61.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 18/18 [00:00<00:00, 613.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: -2.9061\n",
      "Validation Loss: -3.1104, Accuracy: 64.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 18/18 [00:00<00:00, 491.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: -3.8187\n",
      "Validation Loss: -4.0886, Accuracy: 65.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 18/18 [00:00<00:00, 464.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: -4.9138\n",
      "Validation Loss: -5.2877, Accuracy: 65.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 18/18 [00:00<00:00, 548.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: -6.2926\n",
      "Validation Loss: -6.7117, Accuracy: 66.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 18/18 [00:00<00:00, 502.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: -7.8670\n",
      "Validation Loss: -8.4641, Accuracy: 66.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 18/18 [00:00<00:00, 813.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: -9.7904\n",
      "Validation Loss: -10.5272, Accuracy: 68.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 18/18 [00:00<00:00, 467.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: -12.0980\n",
      "Validation Loss: -12.9853, Accuracy: 69.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 18/18 [00:00<00:00, 449.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: -14.8045\n",
      "Validation Loss: -15.9412, Accuracy: 69.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 18/18 [00:00<00:00, 443.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: -18.1080\n",
      "Validation Loss: -19.5862, Accuracy: 69.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 18/18 [00:00<00:00, 678.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: -22.1048\n",
      "Validation Loss: -23.9907, Accuracy: 69.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 18/18 [00:00<00:00, 484.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: -26.9188\n",
      "Validation Loss: -29.3007, Accuracy: 68.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 18/18 [00:00<00:00, 477.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: -32.6598\n",
      "Validation Loss: -35.6355, Accuracy: 68.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 18/18 [00:00<00:00, 517.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: -39.4853\n",
      "Validation Loss: -43.1792, Accuracy: 68.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 18/18 [00:00<00:00, 756.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: -47.4719\n",
      "Validation Loss: -52.0624, Accuracy: 69.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 18/18 [00:00<00:00, 545.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: -56.8270\n",
      "Validation Loss: -62.5149, Accuracy: 71.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 18/18 [00:00<00:00, 518.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: -68.0734\n",
      "Validation Loss: -74.4711, Accuracy: 72.73%\n",
      "Evaluation with ReLU activation:\n",
      "Validation Loss: -74.4711, Accuracy: 72.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 18/18 [00:00<00:00, 647.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.5994\n",
      "Validation Loss: 0.5695, Accuracy: 72.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 18/18 [00:00<00:00, 501.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.5438\n",
      "Validation Loss: 0.5608, Accuracy: 73.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 18/18 [00:00<00:00, 645.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.5163\n",
      "Validation Loss: 0.5502, Accuracy: 75.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 18/18 [00:00<00:00, 443.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.4986\n",
      "Validation Loss: 0.5439, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 18/18 [00:00<00:00, 178.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.4878\n",
      "Validation Loss: 0.5338, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 18/18 [00:00<00:00, 346.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Loss: 0.4797\n",
      "Validation Loss: 0.5286, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 18/18 [00:00<00:00, 504.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.4709\n",
      "Validation Loss: 0.5173, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 18/18 [00:00<00:00, 501.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.4651\n",
      "Validation Loss: 0.5154, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 18/18 [00:00<00:00, 633.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.4604\n",
      "Validation Loss: 0.5090, Accuracy: 76.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 18/18 [00:00<00:00, 630.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Loss: 0.4569\n",
      "Validation Loss: 0.5099, Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 18/18 [00:00<00:00, 579.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.4511\n",
      "Validation Loss: 0.5022, Accuracy: 77.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 18/18 [00:00<00:00, 541.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.4475\n",
      "Validation Loss: 0.4993, Accuracy: 77.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 18/18 [00:00<00:00, 596.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.4435\n",
      "Validation Loss: 0.4936, Accuracy: 77.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 18/18 [00:00<00:00, 504.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.4424\n",
      "Validation Loss: 0.4922, Accuracy: 77.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 18/18 [00:00<00:00, 605.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.4394\n",
      "Validation Loss: 0.4861, Accuracy: 79.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 18/18 [00:00<00:00, 532.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.4356\n",
      "Validation Loss: 0.4894, Accuracy: 78.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 18/18 [00:00<00:00, 168.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.4350\n",
      "Validation Loss: 0.4817, Accuracy: 79.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 18/18 [00:00<00:00, 548.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.4341\n",
      "Validation Loss: 0.4833, Accuracy: 78.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 18/18 [00:00<00:00, 564.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Loss: 0.4328\n",
      "Validation Loss: 0.4824, Accuracy: 78.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 18/18 [00:00<00:00, 349.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.4298\n",
      "Validation Loss: 0.4728, Accuracy: 81.12%\n",
      "Evaluation with LogSoftmax activation:\n",
      "Validation Loss: 0.4728, Accuracy: 81.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn import KLDivLoss\n",
    "\n",
    "# Run with ReLU activation function (Incorrect setup for KLDivLoss)\n",
    "kl_relu_model = SimpleMLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    last_layer_activation_fn=nn.ReLU  # Using ReLU as the last activation function\n",
    ")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "kl_loss_function = KLDivLoss(reduction=\"batchmean\")\n",
    "kl_relu_optimizer = torch.optim.Adam(kl_relu_model.parameters(), lr=0.001)\n",
    "\n",
    "# Instantiate the trainer\n",
    "kl_relu_trainer = SimpleMLPTrainer(\n",
    "    model=kl_relu_model,\n",
    "    criterion=kl_loss_function,\n",
    "    optimizer=kl_relu_optimizer\n",
    ")\n",
    "\n",
    "# Train the model with ReLU activation\n",
    "try:\n",
    "    kl_relu_training_losses = kl_relu_trainer.train(\n",
    "        train_loader=train_loader,\n",
    "        num_epochs=num_epochs,\n",
    "        val_loader=val_loader\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training with ReLU activation: {e}\")\n",
    "\n",
    "# Evaluate the model\n",
    "print('Evaluation with ReLU activation:')\n",
    "kl_relu_val_loss, kl_relu_accuracy = kl_relu_trainer.evaluate(val_loader)\n",
    "\n",
    "# Proper solution: Use LogSoftmax as the last activation function\n",
    "# This ensures that the outputs are log-probabilities as required by KLDivLoss\n",
    "kl_logsoftmax_model = SimpleMLP(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    output_dim=output_dim,\n",
    "    num_hidden_layers=num_hidden_layers,\n",
    "    last_layer_activation_fn=lambda: nn.LogSoftmax(dim=1)  # Using LogSoftmax\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "kl_logsoftmax_optimizer = torch.optim.Adam(kl_logsoftmax_model.parameters(), lr=0.001)\n",
    "\n",
    "# Instantiate the trainer with the corrected model\n",
    "kl_logsoftmax_trainer = SimpleMLPTrainer(\n",
    "    model=kl_logsoftmax_model,\n",
    "    criterion=kl_loss_function,\n",
    "    optimizer=kl_logsoftmax_optimizer\n",
    ")\n",
    "\n",
    "# Train the corrected model\n",
    "kl_logsoftmax_training_losses = kl_logsoftmax_trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    num_epochs=num_epochs,\n",
    "    val_loader=val_loader\n",
    ")\n",
    "\n",
    "# Evaluate the corrected model\n",
    "print('Evaluation with LogSoftmax activation:')\n",
    "kl_logsoftmax_val_loss, kl_logsoftmax_accuracy = kl_logsoftmax_trainer.evaluate(val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your reason for your choice:\n",
    "\n",
    "It seems that there is a significant difference in performance between the two models with ReLU and LogSoftmax activation, with the ReLU-based model achieving only 72.73% accuracy while the LogSoftmax-based model reaches 81.12% accuracy. This discrepancy suggests that the ReLU activation in the output layer of the model is likely causing issues.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "1. **Model with ReLU Activation:**\n",
    "   - **Final Results:**\n",
    "     - Loss: -68.0734 (likely an issue, as losses should not be negative)\n",
    "     - Validation Loss: -74.4711\n",
    "     - Accuracy: 72.73%\n",
    "   \n",
    "   - **Problem with ReLU:**\n",
    "     ReLU is generally used in the hidden layers to introduce non-linearity, but it **should not be used in the output layer** when you're working with loss functions like **KLDivLoss** or any other probabilistic loss (like CrossEntropyLoss). This is because **ReLU does not output probabilities**, and the KLDivLoss expects the model output to be in the form of **log-probabilities** (using `log_softmax`).\n",
    "\n",
    "     ReLU can output values from \\(0\\) to \\(+\\infty\\), which are not suitable for KLDivLoss, which expects the model's predictions to represent probabilities (values between 0 and 1, summing to 1). When the output is not normalized and valid, the loss calculation can become unstable or incorrect, potentially resulting in very large or negative loss values, as seen in your results.\n",
    "\n",
    "2. **Model with LogSoftmax Activation:**\n",
    "   - **Final Results:**\n",
    "     - Loss: 0.4298\n",
    "     - Validation Loss: 0.4728\n",
    "     - Accuracy: 81.12%\n",
    "\n",
    "   - **Why LogSoftmax Works:**\n",
    "     The **LogSoftmax** activation is appropriate for KLDivLoss because it ensures that the output is a **normalized probability distribution**, and its logarithms can be directly compared to the target probability distribution. This makes the loss function work as intended and allows the model to learn more effectively.\n",
    "\n",
    "- **Impact of Changing Activation:**\n",
    "  - **ReLU output** (non-normalized values) leads to incorrect KL divergence calculations, causing poor performance and potentially negative loss values.\n",
    "  - **LogSoftmax output** produces normalized log-probabilities, which aligns with KLDivLoss expectations, leading to more stable and correct training.\n",
    "\n",
    "### **Conclusion:**\n",
    "\n",
    "The significant drop in accuracy (from 81% with LogSoftmax to 72% with ReLU) can be attributed to the use of **ReLU in the output layer**. To resolve this issue, replace the ReLU activation in the output layer with **LogSoftmax** to ensure proper loss calculation and improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. CosineEmbeddingLoss (`torch.nn.CosineEmbeddingLoss`)\n",
    "- **Description:** Measures the cosine similarity between two input tensors, `x1` and `x2`, and computes the loss based on a label `y` that indicates whether the tensors should be similar (`y = 1`) or dissimilar (`y = -1`). Cosine similarity focuses on the angle between vectors, disregarding their magnitude.\n",
    "\n",
    "- **Mathematical Function:** \n",
    "\\begin{equation}\n",
    "  \\text{CosineEmbeddingLoss}(x1, x2, y) = \n",
    "  \\begin{cases} \n",
    "  1 - \\cos(x_1, x_2), & \\text{if } y = 1 \\\\\n",
    "  \\max(0, \\cos(x_1, x_2) - \\text{margin}), & \\text{if } y = -1\n",
    "  \\end{cases}\n",
    "\\end{equation}\n",
    "  where $ \\cos(x_1, x_2) $ is the cosine similarity between the two vectors, and `margin` is a threshold that determines how dissimilar the vectors should be.\n",
    "\n",
    "- **Use Case:** Commonly used in tasks like face verification, image similarity, and other scenarios where the relative orientation of vectors (angle) is more important than their length, such as in embeddings and metric learning.\n",
    "\n",
    "- **Background:** Cosine similarity compares the directional alignment of vectors, making it ideal for high-dimensional data where the magnitude may not be as informative. This loss is particularly useful when training models to learn meaningful embeddings that capture semantic similarity.\n",
    "\n",
    "You'll become more fimiliar with this loss function in future.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization in Machine Learning\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Regularization is a fundamental technique in machine learning that helps prevent overfitting by adding a penalty to the loss function. This penalty discourages the model from becoming too complex, ensuring better generalization to unseen data. In this notebook, you will explore the concepts of regularization, understand different types of regularization techniques, and apply them using Python's popular libraries.\n",
    "\n",
    "## What is Regularization?\n",
    "\n",
    "Regularization involves adding a regularization term to the loss function used to train machine learning models. This term imposes a constraint on the model's coefficients, effectively reducing their magnitude. By doing so, regularization helps in:\n",
    "\n",
    "- **Preventing Overfitting:** Ensures the model does not become too tailored to the training data.\n",
    "- **Improving Generalization:** Enhances the model's performance on new, unseen data.\n",
    "- **Feature Selection:** Especially in L1 regularization, it can drive some coefficients to zero, effectively selecting important features.\n",
    "\n",
    "## Types of Regularization\n",
    "\n",
    "There are several types of regularization techniques, each imposing different constraints on the model's parameters:\n",
    "\n",
    "### 1. L1 Regularization (Lasso)\n",
    "\n",
    "L1 regularization adds the absolute value of the magnitude of coefficients as a penalty term to the loss function. It can lead to sparse models where some feature coefficients are exactly zero.\n",
    "\n",
    "### 2. L2 Regularization (Ridge)\n",
    "\n",
    "L2 regularization adds the squared magnitude of coefficients as a penalty term to the loss function. It tends to shrink the coefficients evenly but does not set them to zero.\n",
    "\n",
    "### 3. Elastic Net\n",
    "\n",
    "Elastic Net combines both L1 and L2 regularization penalties. It balances the benefits of both Lasso and Ridge methods, allowing for feature selection and coefficient shrinkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework Time!\n",
    "Import Iris dataset from sklearn.datasets and apply ridge regression with different alpha values. Then, create a gif that shows the changes of the classification boundary with respect to alpha values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libs that you need and start coding!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import imageio\n",
    "import warnings\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Iris dataset and select Setosa and Versicolor classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris dataset and filter for Setosa and Versicolor classes\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "binary_class_indices = np.where((y == 0) | (y == 1))\n",
    "X = X[binary_class_indices]\n",
    "y = y[binary_class_indices]\n",
    "\n",
    "# Select Sepal Length and Petal Length features\n",
    "X = X[:, [0, 2]]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Function to Plot Decision Boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y, alpha):\n",
    "    # Define the grid (use meshgrid)\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "\n",
    "    # Predict over the grid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Create a figure\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, levels=[-0.1, 0.1, 1.1], colors=['blue', 'red'])\n",
    "\n",
    "    # Scatter plot of the training data\n",
    "    scatter = ax.scatter(\n",
    "        X[:, 0], X[:, 1], c=y, cmap='bwr', edgecolor='k', s=50\n",
    "    )\n",
    "\n",
    "    # Title and labels\n",
    "    ax.set_title(f'MLP Decision Boundary (alpha={alpha})')\n",
    "    ax.set_xlabel('Sepal Length (standardized)')\n",
    "    ax.set_ylabel('Petal Length (standardized)')\n",
    "\n",
    "    # Remove axes for clarity\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Tight layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot to a BytesIO object\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    return Image.open(buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train MLP with Varying Alpha Values and Collect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "def create_decision_boundary_gif(alpha_values, X_train, y_train, n_neurons):\n",
    "\n",
    "    # List to store images\n",
    "    images = []\n",
    "\n",
    "    for idx, alpha in enumerate(alpha_values):\n",
    "        print(f\"Processing alpha={alpha:.4f} ({idx + 1}/{len(alpha_values)})\")\n",
    "\n",
    "        # Create and train the MLP\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(n_neurons,), alpha=alpha, max_iter=1000, random_state=42)\n",
    "        mlp.fit(X_train, y_train)\n",
    "\n",
    "        # Plot decision boundary and get the image\n",
    "        img = plot_decision_boundary(mlp, X_train, y_train, alpha)\n",
    "        images.append(img)\n",
    "\n",
    "    # Save the images as a GIF\n",
    "    gif_filename = 'mlp_classification_boundaries.gif'\n",
    "    images[0].save(\n",
    "        gif_filename,\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=500,\n",
    "        loop=0\n",
    "    )\n",
    "\n",
    "    print(f\"GIF saved as '{gif_filename}'\")\n",
    "\n",
    "    # return the gif\n",
    "    return gif_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alpha=0.0100 (1/20)\n",
      "Processing alpha=0.0162 (2/20)\n",
      "Processing alpha=0.0264 (3/20)\n",
      "Processing alpha=0.0428 (4/20)\n",
      "Processing alpha=0.0695 (5/20)\n",
      "Processing alpha=0.1129 (6/20)\n",
      "Processing alpha=0.1833 (7/20)\n",
      "Processing alpha=0.2976 (8/20)\n",
      "Processing alpha=0.4833 (9/20)\n",
      "Processing alpha=0.7848 (10/20)\n",
      "Processing alpha=1.2743 (11/20)\n",
      "Processing alpha=2.0691 (12/20)\n",
      "Processing alpha=3.3598 (13/20)\n",
      "Processing alpha=5.4556 (14/20)\n",
      "Processing alpha=8.8587 (15/20)\n",
      "Processing alpha=14.3845 (16/20)\n",
      "Processing alpha=23.3572 (17/20)\n",
      "Processing alpha=37.9269 (18/20)\n",
      "Processing alpha=61.5848 (19/20)\n",
      "Processing alpha=100.0000 (20/20)\n",
      "GIF saved as 'mlp_classification_boundaries.gif'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alpha_values = np.logspace(-2, 2, 20)\n",
    "# Define the number of neurons in the hidden layer\n",
    "n_neurons = 10\n",
    "# Create the decision boundary GIF\n",
    "gif_dir = create_decision_boundary_gif(alpha_values, X_train, y_train, n_neurons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your gif should look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "### **Multilayer Perceptron Classification Boundaries**\n",
    "\n",
    "![Classification Boundaries](mlp_classification_boundaries_example.gif)\n",
    "\n",
    "*Figure 1: Demonstration of classification boundaries created by a Multilayer Perceptron (MLP) model.*\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
